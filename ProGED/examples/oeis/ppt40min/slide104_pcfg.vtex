

    Uvod/ Algoritem za odkrivanje ena"cb

    Uvod/ Algoritem za odkrivanje ena"cb/ Lin. Regresija.

  Osnovna ideja algoritema za odkrivanje ena"cb je preprosta, vendar
bi si vseeno rad mimogrede na hitro izposodil "se algoritem *linearne regresije*,
ki ga vsi poznamo oz. smo "ze sli"sali za njega vsaj pri predmetu Statistika 1
na dodiplomskem "studiju, lahko pa tudi pri kak"snem izbirnem predmetu.
Zdelo se mi je, da bi se hitreje poistovetili z algoritmom za odkrivanje ena"cb,
"ce bi ga primerjali z "ze znano linearno regresijo, in tako videli, da tu ni
ni"c novega. 
  Na linearno regresijo bom gledal kot na algoritem z naslednjimi koraki:
	Vhodni podatek imenovan podatkovna mno"zica, je pri linearni regresiji 
matrika X velikosti m x n.
- 0.) Najprej privzamemo linearno ena"cbo oblike y = c0 + c1*x1 + ... + cn*xn (Od tu 
ime linearna)
(( se pravi predpostavljamo, da je y enak linearni kombinaciji x-ov (od x1 do xn) plus konstanta c0.))
/* (( in x1 do xn predstavlajo stolpce od */
(( , kjer i"s"cemo take konstante c0, c1, ... do cn, tako da mi ))
- 1.) Nato definiramo t.i. "napako modela", tj. ciljna funkcija, ki konstante
c0, c1, ..., cn preslika v vsoto:
	sum_i=1 ^m (y _i - c0 + c1*x_i1  + c2*x_i2+ ... cn*x_in )**2 
kjer je n+1 "stevilo stolpcev, m "stevilo vrstic, y_i element matrike X v i-ti vrstici
in (n+1)-tem stolpcu, x_ij element matrike X v i-ti vrstici in j-tem stolpcu.
X = [x|y]   Imamo torej matriko veliki X, ki izgleda tako, da je sestavljena iz bloka velikosti
 m x n, ki ga sestavljajo elementi x_ij in iz bloka m x 1, ki ga predstavlja stolpec y.
(( V strojnem u"cenju mu pravimo ciljni stolpec in se ne nujno vedno nahaja na
 (n+en)-tem mestu, vendar sem poenostavil. ))
	In ta vsota ni ni"c drugega, kot nepregleden zapis tega, da se 
sprehajamo po vrsticah, kjer v vsaki vrstici, vrednost v y stolpcu od"stejemo z 
konstantami pomno"zene vrednosti v ostalih stolpcih, tj. v linearno ena"cbo y = c0 + ...
vstavimo y in ostale stolpce, ter levi strani ena"cbe od"stejemo desno stran. Nato te
razlike kvadriramo in se"stejemo. Spet po tretji strani gre tukaj za (kvadrat) normo vektorja, ki
ga dobimo z mno"zenjem vektorja sestavljenega (ima za komponente) iz konstant c0,...cn in enice, 
z matriko veliki X.
  Sedaj sem "ze za"sel rahlo v detajle. Moj namen ni bil zakomplicirati stvari.
Napaka modela glede na (vhodne podatke) je torej ta vsota, ki jo priredimo konkretnim 
konstantam.
- 2.) Naslednji korak linearne regresije je optimizija teh konstant c0..cn, da bo napaka
modela "cim manj"sa. (S tem si predstavljamo, da najdemo konstante in s tem konkretno
linearno ena"cbo y = c0*x1 + ... + cn*xn, ki se najbolj prilega vhodnim podatkovni mno"zici X.
 ( Optimizira se z odvajanjem, vendar no"cem povdarjati tega.)
- To je to. Izhod so optimalne konstante oz. linearni model.






--- old ----------------------------------------------------
  Preden za"cnem z gramatikami, je smiselno povedati zakaj bi jih sploh uporabili.
Poglejmo si podrobneje kako izgleda algoritem za odkrivanje ena"cb.
Sestavljen je iz ve"c komponent: ( Najbolj grobo lahko govorimo o dveh komponentah:)
  - generator ena"cb
  - evalvacija ena"cb.
V resnici "se tretja faza, ko se moramo odlo"citi, ali je na"s algoritem odkril
kak"sno ena"cbo in katere.
Brez tretje faze imamo torej 
- vhod: "podatki", v katerih odkrivamo ena"cbo.
- izhod: "seznam vseh generiranih ena"cb, in njihova evalvacija"

Kot sem "ze omenil, algoritem za odkrivanje ena"cb generira (veliko) ena"cbe.
Kako jih sploh generira. Odgovor: Gramatika.
((Tako, da predlagam, da si kar pogledamo kaj so gramatike, da bomo vedeli o kak"snih 
ena"cbah sploh cel ta "cas govorimo.))


-2



